{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import time\n",
    "from cacheLSTM.cacheLSTM import cacheLSTM\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "B = 16 # batch-size\n",
    "Di = 64 # input-features\n",
    "Dh = 32 # hidden-state size\n",
    "T = 100 # input sequence len\n",
    "\n",
    "X = torch.randn(T, B, Di, device=cuda_device)\n",
    "h = torch.randn(B, Dh, device=cuda_device)\n",
    "C = torch.randn(B, Dh, device=cuda_device)\n",
    "\n",
    "Wii = torch.randn(Dh, Di, device=cuda_device)\n",
    "Wif = torch.randn(Dh, Di, device=cuda_device)\n",
    "Wig = torch.randn(Dh, Di, device=cuda_device)\n",
    "Wio = torch.randn(Dh, Di, device=cuda_device)\n",
    "\n",
    "Whi = torch.randn(Dh, Dh, device=cuda_device)\n",
    "Whf = torch.randn(Dh, Dh, device=cuda_device)\n",
    "Whg = torch.randn(Dh, Dh, device=cuda_device)\n",
    "Who = torch.randn(Dh, Dh, device=cuda_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128]) torch.Size([128, 32])\n",
      "torch.Size([100, 16, 128])\n",
      "torch.Size([100, 16, 32])\n",
      "clstm cuda on gpu: Forward: 20.590 us \n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# test cache cuda lstm on gpu\n",
    "\n",
    "clstm = cacheLSTM(Di, Dh)\n",
    "clstm_uu = torch.cat([Wii.clone(), Wif.clone(), Wio.clone(), Wig.clone()], 0).transpose(0,1).contiguous()\n",
    "clstm_ww = torch.cat([Whi.clone(), Whf.clone(), Who.clone(), Whg.clone()], 0).contiguous()\n",
    "print(clstm_uu.shape, clstm_ww.shape)\n",
    "\n",
    "clstm.setUW(clstm_uu,clstm_ww)\n",
    "clstm = clstm.to(cuda_device)\n",
    "\n",
    "clstm_x = X.clone()\n",
    "clstm_h = h.clone()\n",
    "clstm_c = C.clone()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# forward\n",
    "start = time.time()\n",
    "clstm_out_h, clstm_out_c = clstm(clstm_x, clstm_h, clstm_c)    \n",
    "torch.cuda.synchronize()\n",
    "clstm_forward = time.time() - start\n",
    "\n",
    "clstm_out_h0 = clstm_out_h[0, :, :]\n",
    "clstm_out_x = clstm_out_h[1:,:,:]\n",
    "print(clstm_out_x.shape)\n",
    "print('clstm cuda on gpu: Forward: {:.3f} us '.format(clstm_forward * 1e6/T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 16, 32])\n",
      "pytorch lstm on gpu: Forward: 14.484 us \n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# test torch lstm on gpu\n",
    "\n",
    "lstm = torch.nn.LSTM(Di, Dh, bias=False)\n",
    "lstm_uu = torch.cat([Wii.clone(), Wif.clone(), Wig.clone(), Wio.clone()], 0).contiguous()\n",
    "lstm_ww = torch.cat([Whi.clone(), Whf.clone(), Whg.clone(), Who.clone()], 0).contiguous()\n",
    "lstm.weight_ih_l0 = torch.nn.Parameter(lstm_uu)\n",
    "lstm.weight_hh_l0 = torch.nn.Parameter(lstm_ww)\n",
    "lstm = lstm.to(cuda_device)\n",
    "\n",
    "lstm_x = X.clone()\n",
    "lstm_h = h.unsqueeze(0).clone()\n",
    "lstm_c = C.unsqueeze(0).clone()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# forward\n",
    "start = time.time()\n",
    "lstm_out_x, (lstm_out_h, lstm_out_c) = lstm(lstm_x, (lstm_h, lstm_c))    \n",
    "print(lstm_out_x.shape)\n",
    "lstm_gpu_forward = time.time() - start\n",
    "\n",
    "print('pytorch lstm on gpu: Forward: {:.3f} us '.format(lstm_gpu_forward * 1e6/T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache lstm cuda on gpu: Forward: 20.590 us \n",
      "pytorch lstm on gpu: Forward: 20.566 us \n"
     ]
    }
   ],
   "source": [
    "# print all results\n",
    "print('cache lstm cuda on gpu: Forward: {:.3f} us '.format(clstm_forward * 1e6/T))\n",
    "print('pytorch lstm on gpu: Forward: {:.3f} us '.format(lstm_gpu_forward * 1e6/T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6.7095e-01, -5.2552e-02,  2.3361e-03, -2.3130e-01,  5.2138e-04,\n",
       "         -7.0899e-01, -8.7565e-07,  3.7662e-02, -1.2957e-07,  7.4257e-05,\n",
       "         -3.1100e-04,  2.3549e-04, -8.4916e-03, -7.6990e-02, -8.9720e-01,\n",
       "         -5.6277e-02,  4.7381e-01, -1.0210e-04, -1.1794e-02,  4.7863e-02,\n",
       "          1.4177e-04,  3.4258e-06,  5.7679e-01, -9.0748e-04,  3.2574e-05,\n",
       "          5.6050e-01, -7.8106e-01, -5.3330e-01,  3.0315e-02, -5.8880e-07,\n",
       "          1.8275e-01, -5.8799e-01], device='cuda:0', grad_fn=<SliceBackward>),\n",
       " tensor([ 6.7357e-01, -5.3687e-02,  1.8194e-03, -2.3104e-01,  7.8410e-04,\n",
       "         -7.0561e-01, -7.2859e-07,  4.1269e-02, -1.2753e-07,  6.5641e-05,\n",
       "         -3.5516e-04,  2.1308e-04, -8.9914e-03, -8.3167e-02, -8.5797e-01,\n",
       "         -5.5491e-02,  4.8048e-01, -1.0232e-04, -1.2082e-02,  4.6014e-02,\n",
       "          1.3134e-04,  3.0148e-06,  5.7085e-01, -6.4880e-04,  2.5527e-05,\n",
       "          5.7099e-01, -7.8045e-01, -5.1147e-01,  3.2279e-02, -5.7538e-07,\n",
       "          1.0764e-01, -5.8434e-01], device='cuda:0', grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(clstm_out_x, lstm_out_x, rtol=0, atol=10)\n",
    "lstm_out_x[9,3,:], clstm_out_x[9,3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6566e-10,  5.9605e-08,  0.0000e+00,  0.0000e+00,  7.2760e-12,\n",
       "         1.8626e-09, -5.9605e-08, -5.9605e-08, -1.7881e-07,  6.4393e-15,\n",
       "        -2.9104e-10,  5.9605e-08,  0.0000e+00, -2.3283e-09, -2.7285e-11,\n",
       "         0.0000e+00, -4.5475e-12,  5.9605e-08,  2.2352e-08,  1.7764e-15,\n",
       "        -7.2760e-11, -1.1642e-10,  1.6007e-10, -1.3411e-07,  9.7145e-17,\n",
       "         2.5466e-11,  4.5475e-13, -2.9559e-12, -1.1921e-07,  2.9843e-13,\n",
       "         1.0800e-12,  2.3283e-10], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out_x[10,1,:] - clstm_out_x[10,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.3733e-10,  1.2713e-02,  2.1779e-04,  3.4586e-07,  2.4343e-05,\n",
       "        -7.1491e-01, -9.4858e-01, -3.4728e-01, -9.1524e-04, -1.0786e-02,\n",
       "         7.4157e-01,  9.7296e-01,  3.7717e-05,  2.4591e-01, -7.4742e-01,\n",
       "        -6.9213e-01,  4.2613e-04, -5.1385e-07,  2.2045e-02,  7.0434e-01,\n",
       "        -9.9542e-01, -2.5549e-01,  8.5770e-04, -9.1106e-01, -4.0740e-05,\n",
       "         8.0394e-03, -7.5224e-01,  9.4008e-05, -2.2697e-01,  9.1121e-02,\n",
       "         6.5521e-02, -7.7733e-06], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually reproducing one time step using the same input and parameters\n",
    "# see if numbers match\n",
    "one_x = lstm_x[0,0,:].squeeze() # (Di)\n",
    "one_h = lstm_h[0,0,:].squeeze() # (Dh)\n",
    "one_c = lstm_c[0,0,:].squeeze() # (Dh)\n",
    "\n",
    "sig = torch.nn.Sigmoid()\n",
    "tanh = torch.nn.Tanh()\n",
    "it = sig(torch.matmul(one_x, Wii.transpose(0,1)) + torch.matmul(one_h, Whi.transpose(0,1)))\n",
    "ft = sig(torch.matmul(one_x, Wif.transpose(0,1)) + torch.matmul(one_h, Whf.transpose(0,1)))\n",
    "gt = tanh(torch.matmul(one_x, Wig.transpose(0,1)) + torch.matmul(one_h, Whg.transpose(0,1)))\n",
    "ot = sig(torch.matmul(one_x, Wio.transpose(0,1)) + torch.matmul(one_h, Who.transpose(0,1)))\n",
    "\n",
    "new_c = ft * one_c + it * gt\n",
    "new_h = tanh(new_c) * ot\n",
    "\n",
    "new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
